{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvm2cm3dR3OD",
        "colab_type": "code",
        "outputId": "3a3fed64-cb6e-4119-da5d-a19645835886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 42.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=b7a6352ee2024af27b5ed5af8f3ba65e7605ef7c233a35d6ae0486deb854a619\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.5\n",
            "openjdk-8-jdk-headless is already the newest version (8u242-b08-0ubuntu3~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEDk6bnSR4FP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's import the libraries we will need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SQLContext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7tsgQmGSBaM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create the session\n",
        "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
        "\n",
        "# create the context\n",
        "sc = pyspark.SparkContext(conf=conf)\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssITaRq8UnxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sqlContext = SQLContext(sc)\n",
        "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/3741049972324885/3783546674231736/4413065072037724/latest.html"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2pg20ZeTLzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('/content/iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgDo5BhVUg-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# Convert target into numerical categories\n",
        "labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgAZRA4KVBvP",
        "colab_type": "code",
        "outputId": "a01f193b-1ab2-4bfc-ff53-bb8b8002b2bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- SepalLength: double (nullable = true)\n",
            " |-- SepalWidth: double (nullable = true)\n",
            " |-- PetalLength: double (nullable = true)\n",
            " |-- PetalWidth: double (nullable = true)\n",
            " |-- Species: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvNOe1iZVF96",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split dataset randomly into Training and Test sets. Set seed for reproducibility\n",
        "(trainingData, testData) = data.randomSplit([0.7, 0.3], seed = 100)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BfNQ_QVYLP3",
        "colab_type": "code",
        "outputId": "3a481247-98dd-417b-fb9d-cf024f7eeba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "trainingData.cache()\n",
        "testData.cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[SepalLength: double, SepalWidth: double, PetalLength: double, PetalWidth: double, Species: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_JpkVArYO9c",
        "colab_type": "code",
        "outputId": "317ce71c-7af5-45c3-f926-dae7066bf1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(trainingData.count())\n",
        "print(testData.count())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n",
            "47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EtrjOKBYVDT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vecAssembler = VectorAssembler(inputCols=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"], outputCol=\"features\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVISxl5xYaHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Train a NaiveBayes model\n",
        "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
        "\n",
        "# Chain labelIndexer, vecAssembler and NBmodel in a \n",
        "pipeline = Pipeline(stages=[labelIndexer, vecAssembler, nb])\n",
        "\n",
        "# Run stages in pipeline and train model\n",
        "model = pipeline.fit(trainingData)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiJ2lL_7Yeyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions on testData so we can measure the accuracy of our model on new data\n",
        "predictions = model.transform(testData)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixH71Z5ZgID",
        "colab_type": "code",
        "outputId": "6f746b25-aa52-49a2-b2e8-c02fe4a07080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "\n",
        "# Display what results we can view\n",
        "predictions.printSchema()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- SepalLength: double (nullable = true)\n",
            " |-- SepalWidth: double (nullable = true)\n",
            " |-- PetalLength: double (nullable = true)\n",
            " |-- PetalWidth: double (nullable = true)\n",
            " |-- Species: string (nullable = true)\n",
            " |-- label: double (nullable = false)\n",
            " |-- features: vector (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ErY3b-DZip-",
        "colab_type": "code",
        "outputId": "79875ff2-619d-4f02-f88d-fbd08151002f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Model Accuracy: \", accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Accuracy:  0.9361702127659575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reG_xbMKZsHY",
        "colab_type": "code",
        "outputId": "561f9445-9a5b-4262-cd41-8a90eda36d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "evaluator.explainParam(\"metricName\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'metricName: metric name in evaluation (f1|weightedPrecision|weightedRecall|accuracy) (default: f1, current: accuracy)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKZsKyptbMng",
        "colab_type": "code",
        "outputId": "a20e8492-894b-47ab-9b8e-4e938ea771ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#confusion matrix\n",
        "from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "# Create (prediction, label) pairs\n",
        "predictionAndLabel = predictions.select(\"prediction\", \"label\").rdd\n",
        "\n",
        "# Generate confusion matrix\n",
        "metrics = MulticlassMetrics(predictionAndLabel)\n",
        "print(metrics.confusionMatrix())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DenseMatrix([[13.,  0.,  0.],\n",
            "             [ 3., 12.,  0.],\n",
            "             [ 0.,  0., 19.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJIYs5PZbtYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}